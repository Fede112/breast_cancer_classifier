{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Hooks tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/fede/Documents/mhpc/breast_cancer_classifier',\n",
       " '/opt/miniconda/envs/phang/lib/python37.zip',\n",
       " '/opt/miniconda/envs/phang/lib/python3.7',\n",
       " '/opt/miniconda/envs/phang/lib/python3.7/lib-dynload',\n",
       " '',\n",
       " '/opt/miniconda/envs/phang/lib/python3.7/site-packages',\n",
       " '/opt/miniconda/envs/phang/lib/python3.7/site-packages/IPython/extensions',\n",
       " '/home/fede/.ipython']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/opt/miniconda/envs/phang/bin/python'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "# from torchsummary import summary\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(800, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda = False\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "model = Net().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "\n",
    "#number of epochs \n",
    "epochs=5\n",
    "\n",
    "#learning rate\n",
    "lr=0.01\n",
    "\n",
    "# keep the momentum to 0, otherwise also freezed parameters \n",
    "# will move for the momentum contribution to parameters evolution\n",
    "momentum=0.0\n",
    "\n",
    "seed=1\n",
    "torch.manual_seed(seed)\n",
    "save_model=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:02, 4627566.99it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 85034.65it/s]                            \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:01, 1562280.88it/s]                           \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 33996.05it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])), batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])), batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6dc8cae518>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(next(iter(test_loader))[0][0][0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_example = next(iter(test_loader))[0][0][0,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hook can be function or a class called by the  __call__(self, *input, *** kwargs ) method of the nn.Module class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty_shape = list(next(iter(test_loader))[0].shape)\n",
    "# empty_shape[0] = 0\n",
    "# activation = {'conv1':torch.empty(empty_shape)}\n",
    "\n",
    "activation = {'conv1':[]}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        pass\n",
    "        activation[name].append(output.detach())\n",
    "    return hook\n",
    "\n",
    "\n",
    "model = Net()\n",
    "# the returned handle allows you to remove the hook\n",
    "handle = model.conv1.register_forward_hook(get_activation('conv1'))\n",
    "x = torch.randn(1, 25)\n",
    "output = model(next(iter(test_loader))[0])\n",
    "output.shape\n",
    "# print(activation['conv1'][0].shape[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle.remove()\n",
    "# hook will no longer trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, verbose = False):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    loss /= len(test_loader.dataset)\n",
    "    acc = 100. * correct / len(test_loader.dataset)\n",
    "    \n",
    "    if verbose:\n",
    "        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            loss, correct, len(test_loader.dataset), acc))\n",
    "    return loss,acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.3156626861572267, 8.27)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model,device,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(activation['conv1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([], size=(0, 20, 24, 24))\n"
     ]
    }
   ],
   "source": [
    "# activation is a list of the features of conv1.\n",
    "# each item in the list corresponds to a batch\n",
    "\n",
    "empty_shape = list(activation['conv1'][0].shape)\n",
    "empty_shape[0] = 0\n",
    "conv1_feat = torch.empty(empty_shape)\n",
    "print(conv1_feat)\n",
    "for i in activation['conv1']:\n",
    "    # print(i.shape)\n",
    "    conv1_feat = torch.cat((conv1_feat, i), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10064, 20, 24, 24])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
